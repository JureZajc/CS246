{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS246-2dPy2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PcHpsEbBy9u",
        "colab_type": "text"
      },
      "source": [
        "Must needed setup before every assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS47h8rY9Va7",
        "colab_type": "code",
        "outputId": "0c268b52-a91c-472c-9a21-0bbb484834e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 57kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 38.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=582c7f54de92cd29e64c49cc962040b0c569cd34b3e5b4b6340830fc1c6af3dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "openjdk-8-jdk-headless is already the newest version (8u232-b09-0ubuntu1~18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYtc6jy19tbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H0F4hoh-DfP",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08wnGItE9thM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arxaOy_J-2fg",
        "colab_type": "text"
      },
      "source": [
        "Setup Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCU9UbhZ-4F7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the Spark Session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# create the Spark Context\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awdFdwO3-S19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Code Variables"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97HyXR9R9tnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s        = 100 # set support threshold\n",
        "topN     = 20  # set top items to show\n",
        "fileName = 'browsing.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-TXh0mc-dw5",
        "colab_type": "text"
      },
      "source": [
        "Code Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjX1z9NB-jQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def single_and_pairs(line):\n",
        "  items  = line.split()\n",
        "  single = [ ( ( item, 'Total'), 1 )  for item in items ]\n",
        "  pairs  = [ ( pair, 1 ) for pair in itertools.permutations(items, 2)]\n",
        "  return single + pairs\n",
        "\n",
        "def sort_filter(counts): #and put the total in the end\n",
        "  total, results = 0, sorted(list(counts), key=lambda (key, count): -count)\n",
        "  for key, count in results:\n",
        "    if key == 'Total':\n",
        "      total = count\n",
        "  if total > s:\n",
        "    results.remove(('Total', total))\n",
        "    results.append(('Total', total))\n",
        "    return results #so Total will be always at the end.\n",
        "\n",
        "def calcCS(pair):\n",
        "  k1, counts, total = pair[0], pair[1], 0\n",
        "  if counts != None:\n",
        "    total = float( counts.pop(-1)[1] )\n",
        "    return [ ((k1, k2), count/total) for k2, count in counts ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTzFEny8AGzL",
        "colab_type": "text"
      },
      "source": [
        "Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoRdALXF-jXg",
        "colab_type": "code",
        "outputId": "bbe38e93-acfd-4420-9b89-3de34caf3656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "confidenceRDD = (sc.textFile(fileName, 12 ) #partition goes here\n",
        "                  .flatMap( single_and_pairs )\n",
        "                  .reduceByKey(lambda a, b: a + b)\n",
        "                  .map(lambda ((key, other), count):(key, (other, count)))\n",
        "                  .groupByKey()\n",
        "                  .mapValues( sort_filter )\n",
        "                  .filter(lambda (key, values): values != None)\n",
        "                  .flatMap( calcCS )\n",
        "                  )\n",
        "\n",
        "print \"Top \" + str(topN)\n",
        "#print confidenceRDD.collect()\n",
        "print confidenceRDD.takeOrdered(topN, lambda (itemSet, score): -score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 20\n",
            "[((u'DAI93865', u'FRO40251'), 1.0), ((u'GRO85051', u'FRO40251'), 0.999176276771005), ((u'GRO38636', u'FRO40251'), 0.9906542056074766), ((u'ELE12951', u'FRO40251'), 0.9905660377358491), ((u'DAI88079', u'FRO40251'), 0.9867256637168141), ((u'FRO92469', u'FRO40251'), 0.983510011778563), ((u'DAI43868', u'SNA82528'), 0.972972972972973), ((u'DAI23334', u'DAI62779'), 0.9545454545454546), ((u'DAI74977', u'GRO83463'), 0.8240740740740741), ((u'DAI20027', u'DAI70456'), 0.8070175438596491), ((u'DAI33885', u'GRO46854'), 0.7407407407407407), ((u'SNA46500', u'GRO44993'), 0.7403846153846154), ((u'SNA81556', u'DAI85309'), 0.7363636363636363), ((u'ELE92920', u'DAI62779'), 0.7326649958228906), ((u'DAI53152', u'FRO40251'), 0.717948717948718), ((u'SNA18336', u'DAI62779'), 0.7136812411847673), ((u'ELE55848', u'GRO32086'), 0.7094594594594594), ((u'DAI74112', u'DAI42493'), 0.6991150442477876), ((u'GRO89004', u'ELE25077'), 0.698051948051948), ((u'GRO81647', u'GRO73461'), 0.6775510204081633)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}